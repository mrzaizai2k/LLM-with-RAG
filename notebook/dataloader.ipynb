{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mrzaizai2k/code_Bao/LLM-with-RAG/notebook\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "try:\n",
    "    print(file_path)\n",
    "except:\n",
    "    file_path = os.path.abspath('')\n",
    "    os.chdir(os.path.dirname(file_path))\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_text_splitters import NLTKTextSplitter, SpacyTextSplitter\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import (BSHTMLLoader, \n",
    "                                                  DirectoryLoader, \n",
    "                                                  Docx2txtLoader, \n",
    "                                                  NewsURLLoader, \n",
    "                                                  PyPDFLoader, \n",
    "                                                  PyMuPDFLoader,\n",
    "                                                  MathpixPDFLoader,\n",
    "                                                  RecursiveUrlLoader, \n",
    "                                                  SeleniumURLLoader, \n",
    "                                                  TextLoader, \n",
    "                                                  UnstructuredHTMLLoader,\n",
    "                                                UnstructuredImageLoader,\n",
    "                                                UnstructuredPowerPointLoader, \n",
    "                                                UnstructuredURLLoader, \n",
    "                                                UnstructuredWordDocumentLoader, \n",
    "                                                YoutubeLoader)\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, TokenTextSplitter, NLTKTextSplitter, SpacyTextSplitter\n",
    "\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from unstructured.cleaners.core import clean_extra_whitespace\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import NougatProcessor, VisionEncoderDecoderModel, pipeline\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = config_parser(data_config_path = 'config/data_config.yaml')\n",
    "model_config = config_parser(data_config_path = 'config/model_config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrzaizai2k/code_Bao/LLM-with-RAG/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# embeddings=HuggingFaceEmbeddings(model_name=model_config.get('embedding_model'),\n",
    "#                                         model_kwargs={'device':take_device()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_url_list = data.get('single_url_list')\n",
    "# loader = NewsURLLoader(urls=single_url_list, \n",
    "#                     post_processors=[clean_extra_whitespace],)\n",
    "# ori_text = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"data/web_data/Chapter_3 - EERD.pdf\"\n",
    "loader = PyMuPDFLoader(pdf_path)\n",
    "ori_text = loader.load()\n",
    "ori_text = combine_short_doc(ori_text, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Specialization\\n\\uf06eSpecialization \\n\\uf071Process of defining a set of subclasses of an entity \\ntype, called superclass\\n\\uf071Defined on the basis of some distinguishing \\ncharacteristic of the entities in the superclass\\n\\uf071May have several specializations of the same entity \\ntype based on different distinguishing characteristics \\n\\uf06eSubclass can have its own:\\n\\uf071Specific attributes (local attributes)\\n\\uf071Specific relationship types\\n13\\nJan - 2015\\n', metadata={'source': 'data/web_data/Chapter_3 - EERD.pdf', 'file_path': 'data/web_data/Chapter_3 - EERD.pdf', 'page': 12, 'total_pages': 67, 'format': 'PDF 1.7', 'title': 'Course:        Database Management Systems Credits: 3', 'author': 'PHONG VU COMPUTER', 'subject': '', 'keywords': '', 'creator': 'Microsoft® PowerPoint® for Office 365', 'producer': 'Microsoft® PowerPoint® for Office 365', 'creationDate': \"D:20190620145018+07'00'\", 'modDate': \"D:20190620145018+07'00'\", 'trapped': ''})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_text[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processor = NougatProcessor.from_pretrained(\"facebook/nougat-base\")\n",
    "# model = VisionEncoderDecoderModel.from_pretrained(\"facebook/nougat-base\")\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model.to(device)\n",
    "# # prepare PDF image for the model\n",
    "# filepath = \"data/web_data/image/slide1.jpg\"\n",
    "# image = Image.open(filepath).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "# # generate transcription (here we only generate 30 tokens)\n",
    "# outputs = model.generate(\n",
    "#     pixel_values.to(device),\n",
    "#     min_length=1,\n",
    "#     max_new_tokens=1024,\n",
    "#     bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
    "# )\n",
    "\n",
    "# sequence = processor.batch_decode(outputs, skip_special_tokens=True)\n",
    "# print(repr(sequence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = (repr(sequence)[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# recursive_url_list = data.get('recursive_url_list')\n",
    "\n",
    "# loader = RecursiveUrlLoader(\n",
    "#     url=recursive_url_list[0], max_depth=2,\n",
    "#       extractor=lambda x: Soup(x, \"html.parser\").text,\n",
    "# )\n",
    "# docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = Docx2txtLoader(\"web_data/sample4.docx\")\n",
    "# data = loader.load()\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urls = [\n",
    "# \"https://e.vnexpress.net/news/travel-guide/binh-phuoc-boasts-jungle-treks-charming-feasts-4673392.html\",\n",
    "# 'https://e.vnexpress.net/news/culture/vietnamese-comic-artist-wins-silver-at-int-l-manga-awards-4695364.html',\n",
    "# ]\n",
    "# loader = UnstructuredURLLoader(urls=urls, \n",
    "#                     post_processors=[clean_extra_whitespace],)\n",
    "# data = loader.load()\n",
    "# print(data)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# youtube_url_list = data.get('youtube_url_list')\n",
    "\n",
    "# loader = YoutubeLoader.from_youtube_url(\n",
    "#     youtube_url_list[0], add_video_info=False\n",
    "# )\n",
    "# data = loader.load()\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cuda\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "class NewsSummarizer:\n",
    "    def __init__(self, summarizer = pipeline(\"summarization\", \n",
    "                                             model=\"Falconsai/text_summarization\", \n",
    "                                             torch_dtype=torch.float16,\n",
    "                                             device = take_device()),\n",
    "                #  translator = GoogleTranslator(),\n",
    "                 chunk_overlap:str = 10,\n",
    "                 max_length:int=200, \n",
    "                 min_length:int=30,\n",
    "                 ):\n",
    "        self.summarizer = summarizer\n",
    "        # self.translator = translator\n",
    "        self.max_length = max_length\n",
    "        self.min_length = min_length\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.text_splitter = self.load_text_splitter()\n",
    "    \n",
    "    def load_text_splitter(self):\n",
    "        text_splitter =  NLTKTextSplitter(chunk_size=1000)\n",
    "        return text_splitter\n",
    "\n",
    "    def summary_text(self,text_chunks:list):\n",
    "        '''Summary short text'''\n",
    "        sum_text= f''\n",
    "        for model_output in self.summarizer(text_chunks, batch_size=8, \n",
    "                                            truncation=\"only_first\",):\n",
    "            text = model_output['summary_text']\n",
    "            sum_text += f'\\n{text}'\n",
    "        return sum_text\n",
    "    \n",
    "    def summary_news(self, news:str)->str:\n",
    "        # trans_news = self.translator.translate(text=news, to_lang='en')\n",
    "        text_chunks = self.text_splitter.split_text(news)\n",
    "        summary_text = self.summary_text(text_chunks)\n",
    "        # summary_text = self.translator.translate(text=summary_text, to_lang='vi')\n",
    "\n",
    "        return summary_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ori_text[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 3:\\nEnhanced Entity-\\nRelationship (EER) Model\\nJan - 2015\\n Contents\\n2\\n1\\nIntroduction to Enhanced-ER Model\\n2\\nSubclasses, Superclasses, and Inheritance\\n3\\nSpecialization and Generalization\\n4\\nConstraints and Characteristics of Specialization \\nand Generalization Hierarchies\\n5\\nCategories\\n6\\nDesign Choices, and Formal Definitions\\nJan - 2015\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ori_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories (1)\n",
      "Category or Union type\n",
      "Represents a single superclass/subclass \n",
      "relationship with more than one superclass\n",
      "Subclass represents a collection of objects that is \n",
      "a subset of the UNION of distinct entity types\n",
      "Attribute inheritance works more selectively\n",
      "Category can be total or partial\n",
      "Some modeling methodologies do not have \n",
      "union types\n",
      "39\n",
      "Jan - 2015\n",
      "\n",
      "-------\n",
      "Categories (2)\n",
      "40\n",
      "Example: Database for vehicle registration, vehicle \n",
      "owner can be a person, a bank (holding a lien on a \n",
      "vehicle) or a company.\n",
      "Category (subclass) OWNER is a subset of the union \n",
      "of the three superclasses COMPANY, BANK, and \n",
      "PERSON \n",
      "A category member must exist in only one of its \n",
      "superclasses\n",
      "Note: The difference from shared subclass, which is \n",
      "a subset of the intersection of its superclasses\n",
      "(shared subclass member must exist in all of its \n",
      "superclasses)\n",
      "Jan - 2015\n",
      "\n",
      "-------\n",
      "Two categories (union types): \n",
      "OWNER and \n",
      "REGISTERED_VEHICLE\n",
      "41\n",
      "Jan - 2015\n",
      " Categories (3)\n",
      "42\n",
      "A category can be total or partial\n",
      "Total\n",
      "\n",
      "Hold the union of all entities in its superclasses.\n",
      "\n",
      "Represented diagrammatically by a double line connecting the\n",
      "category and the circle.\n",
      "Partial\n",
      "\n",
      "Can hold a subset of the union.\n",
      "\n",
      "Represented diagrammatically by a single line connecting the\n",
      "category and the circle.\n",
      "The superclasses of a category may have different key\n",
      "attributes or the same key attribute.\n",
      "E.g.:\n",
      "\n",
      "Different key attributes: OWNER category.\n",
      "\n",
      "The same key attribute: REGISTERED_VEHICLE category.\n",
      "Jan - 2015\n",
      "\n",
      "-------\n",
      "Category vs. Shared Subclass (1)\n",
      "43\n",
      "Jan - 2015\n",
      " Category vs. Shared Subclass (2)\n",
      "44\n",
      "Category\n",
      "A category is the \n",
      "subclass in one single \n",
      "relationship.\n",
      "This relationship has \n",
      "more than one \n",
      "superclass representing \n",
      "different entity types.\n",
      "Shared Subclass\n",
      "A shared subclass is the \n",
      "subclass in more than \n",
      "one distinct relationship \n",
      "(multiple inheritance).\n",
      "Each of these \n",
      "relationships has a \n",
      "single superclass.\n",
      "Jan - 2015\n",
      "\n",
      "-------\n",
      "Category vs. Shared Subclass (3)\n",
      "45\n",
      "Category\n",
      "A member entity of a category \n",
      "must exist in only one of its \n",
      "superclasses (OR).\n",
      "• E.g.: An OWNER may be a COMPANY, \n",
      "a BANK, or a PERSON.\n",
      "A category is a subset of the \n",
      "union of its superclasses.\n",
      "• E.g.: OWNER is a subset of the union \n",
      "of the three superclasses.\n",
      "Shared Subclass\n",
      "An member entity of a shared \n",
      "subclass must exist in all its \n",
      "superclasses (AND).\n",
      "• E.g.: An engineering manager must \n",
      "be an ENGINEER, a MANAGER, and \n",
      "a SALARIED_EMPLOYEE.\n",
      "A shared subclass is a subset of \n",
      "the intersection of its superclasses.\n",
      "• E.g.: ENGINEERING_MANAGER is a \n",
      "subset of the intersection of the three \n",
      "superclasses.\n",
      "Jan - 2015\n",
      "\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for i, txt in enumerate(ori_text[30:35]):\n",
    "    print(f\"{txt.page_content}\\n-------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(texts):\n",
    "    for i, t in enumerate(texts):\n",
    "        print(f\"{texts[i]}\\n-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Example of a Generalization\\n17\\nJan - 2015\\n Specialization and Generalization (1)\\n18\\n\\uf06eDiagrammatic notation sometimes used to \\ndistinguish between generalization and \\nspecialization\\n\\uf071Arrow pointing to the generalized superclass \\nrepresents a generalization \\n\\uf071Arrows pointing to the specialized subclasses \\nrepresent a specialization \\n\\uf071We do not use this notation because it is often \\nsubjective as to which process is more appropriate for \\na particular situation \\n\\uf071We advocate not drawing any arrows in these \\nsituations \\nJan - 2015\\n', metadata={'source': 'data/web_data/Chapter_3 - EERD.pdf', 'file_path': 'data/web_data/Chapter_3 - EERD.pdf', 'page': 17, 'total_pages': 67, 'format': 'PDF 1.7', 'title': 'Course:        Database Management Systems Credits: 3', 'author': 'PHONG VU COMPUTER', 'subject': '', 'keywords': '', 'creator': 'Microsoft® PowerPoint® for Office 365', 'producer': 'Microsoft® PowerPoint® for Office 365', 'creationDate': \"D:20190620145018+07'00'\", 'modDate': \"D:20190620145018+07'00'\", 'trapped': ''})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_text[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of a Generalization\n",
      "17\n",
      "Jan - 2015\n",
      " Specialization and Generalization (1)\n",
      "18\n",
      "Diagrammatic notation sometimes used to \n",
      "distinguish between generalization and \n",
      "specialization\n",
      "Arrow pointing to the generalized superclass \n",
      "represents a generalization \n",
      "Arrows pointing to the specialized subclasses \n",
      "represent a specialization \n",
      "We do not use this notation because it is often \n",
      "subjective as to which process is more appropriate for \n",
      "a particular situation \n",
      "We advocate not drawing any arrows in these \n",
      "situations \n",
      "Jan - 2015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = ori_text[12].page_content\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of a Generalization\n",
      "17\n",
      "Jan - 2015\n",
      " Specialization and Generalization (1)\n",
      "18\n",
      "Diagrammatic notation sometimes used to \n",
      "distinguish between generalization and \n",
      "specialization\n",
      "Arrow pointing to the generalized superclass \n",
      "represents a generalization \n",
      "Arrows pointing to the specialized subclasses \n",
      "represent a specialization \n",
      "We do not use this notation because it is often \n",
      "subjective as to which process is more appropriate for \n",
      "a particular situation \n",
      "We advocate not drawing any arrows in these \n",
      "situations \n",
      "Jan - 2015\n",
      "\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "token_text_splitter = TokenTextSplitter(chunk_size=150, chunk_overlap=10)\n",
    "token_texts = token_text_splitter.split_text(text)\n",
    "check(token_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of a Generalization\n",
      "17\n",
      "Jan - 2015\n",
      " Specialization and Generalization (1)\n",
      "18\n",
      "Diagrammatic notation sometimes used to \n",
      "distinguish between generalization and \n",
      "specialization\n",
      "Arrow pointing to the generalized superclass \n",
      "represents a generalization \n",
      "Arrows pointing to the specialized subclasses \n",
      "represent a specialization \n",
      "We do not use this notation because it is often \n",
      "subjective as to which process is more appropriate for \n",
      "a particular situation \n",
      "We advocate not drawing any arrows in these \n",
      "situations \n",
      "Jan - 2015\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "nltk_text_splitter = NLTKTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "nltk_texts = nltk_text_splitter.split_text(text)\n",
    "check(nltk_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_check(text_chunks):\n",
    "    sum_text = NewsSummarizer().summary_text(text_chunks)\n",
    "    print(sum_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but your input_length is only 118. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=59)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generalization and Generalization (1) 18 Diagrammatic notation sometimes used to distinguish between generalization and specialization Arrow pointing to the generalized superclass represents a generalization . We do not use this notation because it is often subjective as to which process is more appropriate for a particular situation .\n"
     ]
    }
   ],
   "source": [
    "sum_check(token_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but your input_length is only 118. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=59)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generalization and Generalization (1) 18 Diagrammatic notation sometimes used to distinguish between generalization and specialization Arrow pointing to the generalized superclass represents a generalization . We do not use this notation because it is often subjective as to which process is more appropriate for a particular situation .\n"
     ]
    }
   ],
   "source": [
    "sum_check(nltk_texts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
